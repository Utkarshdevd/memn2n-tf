<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Implementing Memory networks in Tensorflow | My New Hugo Site</title>
    <link rel="stylesheet" href="/memn2n-tf/css/style.css" />
    <link rel="stylesheet" href="/memn2n-tf/css/fonts.css" />
    
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css">
    <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
</head>

  


  <body>
    <nav>
    <ul class="menu">
      
    </ul>
    <hr/>
    </nav>

<div class="article-meta">
<h1><span class="title">Implementing Memory networks in Tensorflow</span></h1>

<h2 class="date">2017/07/19</h2>
</div>

<main>


<p>We will implement the End to End memory networks <a href="https://arxiv.org/abs/1503.08895" title="End to End memory networks">paper</a>. We shall use Dom Lun’s <a href="https://github.com/domluna/memn2n/blob/master/data_utils.py" title="reader functions">reader functions</a>  and concentrate on getting the simplest implementation of the network. In this process we will learn how to manipulate the memories to get the output. We shall use Tensorflow 1.0.1 for this code and loosely use the code structure from Hafner’s <a href="https://danijar.com/structuring-your-tensorflow-models/" title="Hafner’s blog">blog</a>. The final code of this blog is <a href="https://github.com/Utkarshdevd/memn2n-TFcode" title="Blog code">here</a>.</p>

<blockquote>
<p>This blog assumes a basic understanding of Tensorflow and intermediate understanding of Python 2 or Python 3</p>
</blockquote>

<h2 id="what-is-a-memory-network">What is a memory network?</h2>

<p>Traditionally RNNs and its variants(LSTM, GRU) have been phenomenally successful in PoS tagging and other NLP tasks. But have failed when it comes to reasoning tasks, where they have to somehow remember items as they lack a ‘memory’ component. Thus these networks were provided an explicit memory for such tasks to overcome restrictions on long term dependencies. They also use soft attention to further model the reading and writing of these memories. 
First we will understand this particular Memory network abbreviated as MemN2N. Here is the diagram of a simple network of 1 hop and the original code in Matlab.</p>


<figure >
    
        <img src="../../images/simpleMemn2n.jpg" />
    
    
    <figcaption>
        <h4>A simple 1-hop memory network</h4>
        
    </figcaption>
    
</figure>


<p>We will concentrate on replicating the bAbI task in the paper without temporal encoding. That is left as an exercise to the reader.
Now lets see the MemN2N in general and code it up part by part.</p>

<h2 id="parts-of-memn2n">Parts of MemN2N</h2>

<p>In contrast to hard attention used in earlier models of Memory networks, MemN2N uses soft attention over the memory to select them. This is done using a simple softmax.</p>

<h3 id="input">Input</h3>

<p>We embed all sentences (<code>$x_i$</code>), questions (<code>$q$</code>) and answers (<code>$a$</code>) using different embedding matrices. So we keep a dictionary of all words that we see in the dataset, $V$. Such that each word is mapped to its index.
Input consists of making the embedding matrices <code>$C$</code>, <code>$A$</code> and <code>$B$</code>. Where <code>$C$</code> and <code>$A$</code> map to memory vectors (<code>$m_i$</code>) and output vectors (<code>$c_i$</code>) respectively. For making each of these we will need to define an embedding size and number of memories. Since we have a OOP approach, we can get those variables from a FLAG file that is reccomended from tensorflow. So we create a <code>_create_placeholders</code> function and call the placeholder object to hold the data. You know placeholders right?</p>

<blockquote>
<h4 id="what-are-placeholders">What are placeholders?</h4>

<p>Tensorflow seperates the data feeding process with the actual learning machine. This is done by defining placeholders, think of them as buckets that you place the data in each time step or what every type of interval you like to define. And the learning algorithms has its matrices and data structs collect that data and do its process.</p>
</blockquote>

<p>Okay, now lets make the <code>_create_placeholders</code> function,</p>

<pre><code>def _create_placeholders(self):
	self._stories = tf.placeholder(tf.int32, [None, self._memory_size, self._sentence_size], name=&quot;stories&quot;)
	self._queries = tf.placeholder(tf.int32, [None, self._sentence_size], name=&quot;queries&quot;)
	self._answers = tf.placeholder(tf.int32, [None, self._vocab_size], name=&quot;answers&quot;)
</code></pre>

<p>Now we make the embedding matrices in 2 steps, making the placeholders first,</p>

<pre><code>	nil_word = tf.zeros([1, self._embedding_size])
	A_placeholder = tf.concat(axis=0, values=
		[nil_word, self._normal_init([self._vocab_size-1, self._embedding_size])])
	C_placeholder = tf.concat(axis=0, values=
		[nil_word, self._normal_init([self._vocab_size-1, self._embedding_size])])
</code></pre>

<p><code>nil_word</code> is the empty word, meaning a null value we add as the first entry in the placeholder.
Then we make the embedding matrices, inside the <code>memn2n</code> scope. Here we add A, we name it A_1 as the code is kept open to the weight tying that the paper says it experimented with, you can make more A_k type matrices if you want to untie the weights. We follow the adjacent weight sharing described in the paper, consecutive A matrices are equal to the previous C matrix.
<code>$$ A_k = C_{k-1}$$</code></p>

<pre><code>	with tf.variable_scope(&quot;memn2n&quot;):
		self.A_1 = tf.Variable(A_placeholder, name=&quot;A&quot;)
</code></pre>

<p>Now we add the idea of hops, more A type matrices can be added in the same fashion. Here we add matrices to an array corresponding to the C matrix at each hop. Number of hops in the memory are denoted by <code>n_hops</code>. Each hop has its own scope.</p>

<pre><code>	with tf.variable_scope(&quot;memn2n&quot;):
		self.A_1 = tf.Variable(A_placeholder, name=&quot;A&quot;)
		self.C = []
		for hop_number in range(self._hops):
			with tf.variable_scope(&quot;hop_number{}&quot;.format(hop_number)):
				self.C.append(tf.Variable(C_placeholder, name=&quot;C&quot;))
</code></pre>

<p>we also add the learning rate as a olaceholder, so this lets us change the rate as we learn. The MemN2N paper uses simulated annealing for this.</p>

<pre><code>	self._lr = tf.placeholder(tf.float32, [], name=&quot;learning_rate&quot;)
</code></pre>

<p>By default we keep the number of hops as <code>$k=3$</code> as reported in the paper with good results, with weight sharing. This is how the paper shows it,

<figure class="center">
    
        <img src="../../images/nHop.png" width="400" />
    
    
    <figcaption>
        <h4>A 3-hop network</h4>
        
    </figcaption>
    
</figure>
</p>

<h3 id="memory">Memory</h3>

<p>Before we go on to make the embedding part of code, Section 4.1 describes the position endcoding to define a sense of ordering in a sentence. This will encode how the position of the words matter, keeping the last word independent as it hints the end. The Matlab <a href="https://github.com/facebook/MemNN/blob/946c4784b59dcf053bbbbb9637d6814bc152c276/MemN2N-babi-matlab/build_model.m" title="Position encoding code">code</a> has the function defined, we will just convert it to a python function.</p>

<pre><code>def position_encoder(embedding_size, sentence_size):
	encoding = np.ones((embedding_size, sentence_size), dtype=np.float32)
	# 1 based indexing
	for k in range(1, embedding_size+1):
		for j in range(1, sentence_size+1):
			encoding[k-1, j-1] = (1 - j/sentence_size) - (k/embedding_size) * (1 - 2 * j/sentence_size)
	
	# make last word immune to encoding
	encoding[:, -1] = 1.0
	return np.transpose(encoding)
</code></pre>

<p>We can now add the embedding lookup code, tensorflow gives functions to make the conversion from a sentence to its embedded version. Since this is the part where the actual network gets built we make a new <code>_inference</code> function. Here, We make the <code>$B$</code> matrix, which uses the same first A matrix for looking up the words in the query. So the same set of embeddings are used for the question and the sentence. Going back the the 1 hop network image, we see that <code>$B$</code> gives us the resultant vector <code>$u$</code>.
The <code>reduce_sum</code> function, in the following code, computes the dot product between the encoding and the embeddings for the question, along the <code>axis=1</code>. This provides the weighting to each word based on the positional encoding.</p>

<pre><code>def _inference(self):
	with tf.variable_scope(&quot;memn2n&quot;):
		# adjacent weight, B = A_1
		B = tf.nn.embedding_lookup(self.A_1, self._queries)
		u_1 = tf.reduce_sum(B * self._encoding, 1)
		u = [u_1]

</code></pre>

<p>Now to get the <code>$p_i$</code> we have to get <code>$m_i$</code> and use it in the following operation with the softmax. This probability can be understood as a soft attention over the memories, what memory is most important for this question that is asked.
<code>$$p_i = Softmax(u^Tm_i)$$</code>
Lets start with getting <code>$m_i$</code>, from its correspoding lookup. We do this at each hop, this is what the first hop looks like,</p>

<pre><code>for hop_number in range(self._hops):
	if hop_number == 0:
		# first hop, C_1 = A_1
		A_lookup = tf.nn.embedding_lookup(self.A_1, self._stories)
		m_A = tf.reduce_sum(A_lookup * self._encoding, 1)
</code></pre>

<p>In the code above, <code>m_A</code> has the encoding for the story sentences.</p>

<pre><code>	else:
		with tf.variable_scope(&quot;hop_number{}&quot;.format(hop_number-1)):
			# A_k+1 = C_k --&gt; C[-1], topmost C
			A_lookup = tf.nn.embedding_lookup(self.C[hop_number-1], self._stories)
			m_A = tf.reduce_sum(A_lookup * self._encoding, 1)

</code></pre>

<p>This is the adjacent weight sharing in action, for the hops after the first we define <code>m_A</code> as the last <code>C</code> matrix that is positionally encoded.</p>

<pre><code>	u_temp = tf.transpose(tf.expand_dims(u[-1], -1), [0, 2, 1])
	dot = tf.reduce_sum(m_A * u_temp, 2)
	print(dot.get_shape())
	prob = tf.nn.softmax(dot)
	P = tf.transpose(tf.expand_dims(prob, -1), [0, 2, 1])
</code></pre>

<p>Since we have the training done in batches, all matrices reflect that. We arrange <code>u_temp</code> such that we can align it with the memories. This arrangement corresponds to the <code>$u^T$</code> in the formula. We then compute the dot product, and softmax over it which normalizes it, resulting in <code>P</code>, which we rearrange to the original dimensions.
Now we make <code>C</code>,</p>

<pre><code>	with tf.variable_scope(&quot;hop_number{}&quot;.format(hop_number)):
		C_lookup = tf.nn.embedding_lookup(self.C[hop_number], self._stories)
		m_C = tf.reduce_sum(C_lookup * self._encoding, 1)
</code></pre>

<p>We make <code>m_C</code> for each hop, and store these in the global <code>C</code> array so we can share the weights with the adjacent <code>A_k</code> matrix.</p>

<h3 id="output">Output</h3>

<p>Having gotten <code>P</code>, we now need to do the soft attention over the matrix <code>C</code> that corresponds to preferring a particular sentence as releveant to the query. We combine <code>$c_i$</code> and <code>$p_i$</code>,
<code>$$o = \sum_{i} p_i c_i$$</code>
Which tranlates to the following code,</p>

<pre><code>	m_C_temp = tf.transpose(m_C, [0, 2, 1])
	o_k = tf.reduce_sum(m_C_temp * P, 2)
	u_k = u[-1] + o_k
	u.append(u_k)
</code></pre>

<p>We compute <code>$o$</code> at the end of each hop, we add it to an array. And now we make the answer.</p>

<h3 id="answer">Answer</h3>

<p>The answer <code>$\hat{a}$</code> is computed like this,
<code>$$\hat{a} = Softmax(W(o + u))$$</code>
The matrix <code>$W$</code> transforms to the logits corresponing to the words that could be answers, here this could also be the final vector that could be fed to an RNN to generate more verbose answers. The bAbI has 1 word answers, so we just softmax these logits to get probablility of each word to be answer. Here is the code that does this,</p>

<pre><code>	# W = last C, weight tying
	with tf.variable_scope(&quot;hop_number{}&quot;.format(hop_number)):
		self._logits = tf.matmul(u_k, tf.transpose(self.C[-1], [1,0]))
		self._scores = tf.nn.softmax(self._logits)
</code></pre>

<p>This concludes the <code>_inference</code> function.</p>

<h3 id="learning">Learning</h3>

<p>Now we add the loss function, the paper uses cross entropy sum and we make the appropriate scopes.</p>

<pre><code>	def _create_loss(self):
		with tf.variable_scope(&quot;loss&quot;):
			cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=self._scores, labels=tf.cast
				(self._answers, tf.float32), name=&quot;cross_entropy&quot;)
			self._loss = tf.reduce_sum(cross_entropy, name=&quot;cross_entropy_sum&quot;)
</code></pre>

<p>The <code>softmax_cross_entropy_with_logits</code> function takes in the logits or scores we calculated at the end of the inference stage, and the training answers.
Then we make the accuracy that we keep printing at each learning step,</p>

<pre><code>		with tf.variable_scope(&quot;accuracy&quot;):
			self.predictions = tf.argmax(self._scores, 1, name=&quot;predictions&quot;)
			correct_predictions = tf.equal(self.predictions, tf.argmax(self._answers, 1))
			self._accuracy = tf.reduce_mean(tf.cast(correct_predictions, &quot;float&quot;), name=&quot;accuracy&quot;)
			#self._predictions = tf.argmax(self._logits, 1, name=&quot;prediction&quot;)
			self._prediction_probabilities = tf.nn.softmax(self._logits, name=&quot;predict_prob&quot;)
</code></pre>

<p>Now we set the GD optimizer and perform the gradient clipping that the paper uses,</p>

<pre><code>	def _create_optimizer(self):
		with tf.variable_scope(&quot;optimizer&quot;):
			self._global_step = tf.Variable(0, name=&quot;global_step&quot;, trainable=False)
			self._optimizer = tf.train.GradientDescentOptimizer(learning_rate=self._lr)
			grads_and_vars = self._optimizer.compute_gradients(loss=self._loss)
			grads_and_vars = [(tf.clip_by_norm(g, self._max_grad_norm), v) for g,v in grads_and_vars]
			# noise for temporal
			# zeronilslot
			self._train = self._optimizer.apply_gradients(grads_and_vars, global_step=self._global_step)
</code></pre>

<p>There are comments for adding random noise to the temporal matrix that the paper used to allow some notion of time steps in the training, this is left as an exercise for the reader.
The <code>self._global_step</code> is a graph level global variable that we use as a counter.
So now we have all the matrices and functions that we can attach the summary writer to. This next step allows us to use the tensorboard and visualize our training and testing progress.</p>

<h3 id="summaries">Summaries</h3>

<p>This is how we create a File Writer object in tensorflow versions above 1.0,</p>

<pre><code>def _create_summary(self):
	writer = tf.summary.FileWriter(&quot;test&quot;, self._sess.graph)
	timestamp = str(int(time.time()))
	out_dir = os.path.abspath(os.path.join(os.path.curdir, &quot;runs&quot;, timestamp))
	print(&quot;Writing to {}\n&quot;.format(out_dir))
</code></pre>

<p>We then attach a writer to the loss and the accuracy variables,</p>

<pre><code>	loss_summary = tf.summary.scalar(&quot;loss&quot;, self._loss)
	acc_summary = tf.summary.scalar(&quot;accuracy&quot;, self._accuracy)
</code></pre>

<p>Now we seperate the training and the testing recordings, here is the training records in an appropriately named folder,</p>

<pre><code>	self._train_summary_op = tf.summary.merge([loss_summary, acc_summary])
	train_summary_dir =  os.path.join(out_dir, &quot;summaries&quot;, &quot;train&quot;)
	self._train_summary_writer = tf.summary.FileWriter(train_summary_dir, self._sess.graph)
</code></pre>

<p>this is the dev or test records,</p>

<pre><code>	self._dev_summary_op = tf.summary.merge([loss_summary, acc_summary])
	dev_summary_dir = os.path.join(out_dir, &quot;summaries&quot;, &quot;dev&quot;)
	self._dev_summary_writer = tf.summary.FileWriter(dev_summary_dir, self._sess.graph)
</code></pre>

<p>Now we add the checkpoints that record all the graph variables and values so, you can keep saving them. This is reccomended if you have timeouts on your cpu/gpu servers, so you can pickup training where you left it.</p>

<pre><code>	# Checkpointing
	checkpoint_dir = os.path.abspath(os.path.join(out_dir, &quot;checkpoints&quot;))
	self._checkpoint_prefix = os.path.join(checkpoint_dir, &quot;model&quot;)
	# Tensorflow assumes this directory already exists so we need to create it
	if not os.path.exists(checkpoint_dir):
	    os.makedirs(checkpoint_dir)
	self._saver = tf.train.Saver(tf.global_variables())
</code></pre>

<h3 id="feeding-data">Feeding data</h3>

<p>To make this graph work we need to use the placeholders we had created and provide the feeder functions to it,</p>

<pre><code>def _train_step(self, stories, queries, answers, lr):
	feed_dict = {
		self._stories: stories,
		self._queries: queries,
		self._answers: answers,
		self._lr: lr
	}
	_, step, summaries, loss, accuracy = self._sess.run(
		[self._train, self._global_step, self._train_summary_op, self._loss, self._accuracy],
		feed_dict=feed_dict)
	time_str = datetime.datetime.now().isoformat()
	print(&quot;{}: step {}, loss {:g}, acc {:g}&quot;.format(time_str, step, loss, accuracy))
	self._train_summary_writer.add_summary(summaries, step)
</code></pre>

<p>And this is for the dev or test step,</p>

<pre><code>def _dev_step(self, stories, queries, answers):
	feed_dict = {
		self._stories: stories,
		self._queries: queries,
		self._answers: answers,
	}
	step, summaries, loss, accuracy  = self._sess.run(
		[self._global_step, self._dev_summary_op, self._loss,  self._accuracy],
		feed_dict=feed_dict)
	time_str = datetime.datetime.now().isoformat()
	print(&quot;{}: step {}, loss {:g}, acc {:g}&quot;.format(time_str, step, loss, accuracy))
	self._dev_summary_writer.add_summary(summaries, step)
</code></pre>

<p>The <code>feed_dict</code> keeps the stories, queries, answers and the learning rate, it attaches it to the placeholders we had created earlier.
We then call the run function, give it the array of variables to be computed and returned, then we print them. Finally we add the summary variables.</p>

<h3 id="running">Running</h3>

<p>Now lets go through the building and running of the graph,</p>

<pre><code>def build_and_run(self, trainS, valS, trainQ, valQ, trainA, valA, batches):
	self._create_placeholders()
	self._inference()
	self._create_loss()
	self._create_optimizer()
	self._create_summary()
	self._sess.run(tf.global_variables_initializer())
	lr = self._learning_rate
</code></pre>

<p>Its easy to see how the graph builds up and the loss, optimizers get attached. Then the <code>_sess</code> is used to run the initializer, building the graph.
Now to the training and testing,</p>

<pre><code>	for step in range(1, self._epochs):

		np.random.shuffle(batches)
		for start,end in batches:
			s = trainS[start:end]
			q = trainQ[start:end]
			a = trainA[start:end]

			print(&quot;TRAIN STEP&quot;)
			self._train_step(stories=s, queries=q, answers=a, lr=lr)
			current_step = tf.train.global_step(self._sess, self._global_step)
</code></pre>

<p>This part shuffles the entire dataset, using the reader functions we borrow from Dom Lun,
Now we write the simulated annealing part,</p>

<pre><code>			if current_step % self._evaluate_every == 0:
				print(&quot;DEV STEP:&quot;)
				self._dev_step(valS, valQ, valA)
			if current_step % self._checkpoint_every == 0:
				save_path = self._saver.save(self._sess, self._checkpoint_prefix, global_step=current_step)
				print(&quot;Saving checkpoints to {}\n&quot;.format(save_path))
			if (current_step+1) % self._anneal_every == 0 and current_step &lt; 100:
				lr /= 2
</code></pre>

<p>So after each time step interval, we keep reducing the learning rate by half, so the local minima is atleast assured.</p>

<h3 id="visualizing-training-and-testing-using-tensorboard">Visualizing training and testing using Tensorboard</h3>

<p>To be added&hellip;</p>

</main>

  <footer>
  <script src="//yihui.name/js/math-code.js"></script>
<script async src="//cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

<script async src="//yihui.name/js/center-img.js"></script>

  
  </footer>

</body>
</html>

